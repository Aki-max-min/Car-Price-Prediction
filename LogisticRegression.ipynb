{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599453\n",
      "Iteration 100, Loss: nan\n",
      "Iteration 200, Loss: nan\n",
      "Iteration 300, Loss: nan\n",
      "Iteration 400, Loss: nan\n",
      "Iteration 500, Loss: nan\n",
      "Iteration 600, Loss: nan\n",
      "Iteration 700, Loss: nan\n",
      "Iteration 800, Loss: nan\n",
      "Iteration 900, Loss: nan\n",
      "\n",
      "Final Weights: [ 2.505  1.923 46.     3.903]\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3 2]\n",
      " [0 0]]\n",
      "Accuracy: 0.60\n",
      "Precision: 0.60\n",
      "Recall: 1.00\n",
      "F1 Score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21061/178846135.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "/tmp/ipykernel_21061/178846135.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
      "/tmp/ipykernel_21061/178846135.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [3, 22000, 1],\n",
    "    [6, 75000, 0],\n",
    "    [2, 14000, 1],\n",
    "    [8, 85000, 0],\n",
    "    [4, 50000, 1]\n",
    "])\n",
    "\n",
    "y = np.array([1, 0, 1, 0, 1])\n",
    "\n",
    "w = np.zeros(X.shape[1] + 1)  \n",
    "alpha = 0.01  \n",
    "iterations = 1000\n",
    "\n",
    "# Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Training using Gradient Descent\n",
    "for i in range(iterations):\n",
    "    # Add Bias Term (x0 = 1)\n",
    "    X_bias = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate Linear Combination (z = w0 + w1*x1 + w2*x2 + w3*x3)\n",
    "    z = np.dot(X_bias, w)\n",
    "\n",
    "    # Apply Sigmoid Function\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    # Compute Loss\n",
    "    loss = loss_function(y, y_pred)\n",
    "\n",
    "    # Calculate Gradients\n",
    "    gradient = np.dot(X_bias.T, (y_pred - y)) / len(y)\n",
    "\n",
    "    # Update Weights\n",
    "    w -= alpha * gradient\n",
    "\n",
    "    # Print loss every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nFinal Weights:\", w)\n",
    "\n",
    "# Prediction Function\n",
    "def predict(X_new):\n",
    "    X_new_bias = np.c_[np.ones(X_new.shape[0]), X_new]\n",
    "    z = np.dot(X_new_bias, w)\n",
    "    return (sigmoid(z) >= 0.5).astype(int)\n",
    "\n",
    "y_pred = predict(X)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy: {accuracy(y, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision(y, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall(y, y_pred):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0.5 0.5 0.5 0.5 0.5]\n",
      "\n",
      "Loss: 0.6931471805599453\n",
      "\n",
      "Gradient:\n",
      "[-1.0e-01  5.0e-01  7.4e+03 -3.0e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 1.0e-03 -5.0e-03 -7.4e+01  3.0e-03]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[-1628000.011 -5550000.029 -1036000.006 -6290000.039 -3700000.016]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[7.0e-03 1.3e-02 9.8e+01 9.0e-03]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[2156000.055 7350000.085 1372000.042 8330000.111 4900000.068]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[4.0e-01 2.8e+00 3.2e+04 0.0e+00]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 3.00e-03 -1.50e-02 -2.22e+02  9.00e-03]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ -4884000.033 -16650000.087  -3108000.018 -18870000.117 -11100000.048]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 9.0e-03  3.0e-03 -5.0e+01  1.5e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[-1099999.967 -3749999.973  -699999.97  -4249999.967 -2499999.964]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[1.50e-02 2.10e-02 1.22e+02 2.10e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ 2684000.099  9150000.141  1708000.078 10370000.183  6100000.12 ]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[4.0e-01 2.8e+00 3.2e+04 0.0e+00]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 1.10e-02 -7.00e-03 -1.98e+02  2.10e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ -4355999.989 -14850000.031  -2771999.982 -16830000.045  -9899999.996]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 1.7e-02  1.1e-02 -2.6e+01  2.7e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ -571999.923 -1949999.917  -363999.934 -2209999.895 -1299999.912]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[2.30e-02 2.90e-02 1.46e+02 3.30e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ 3212000.143 10950000.197  2044000.114 12410000.255  7300000.172]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[4.0e-01 2.8e+00 3.2e+04 0.0e+00]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 1.90e-02  1.00e-03 -1.74e+02  3.30e-02]\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10\n",
      "X_bias (With Bias Term Added):\n",
      "[[1.0e+00 3.0e+00 2.2e+04 1.0e+00]\n",
      " [1.0e+00 6.0e+00 7.5e+04 0.0e+00]\n",
      " [1.0e+00 2.0e+00 1.4e+04 1.0e+00]\n",
      " [1.0e+00 8.0e+00 8.5e+04 0.0e+00]\n",
      " [1.0e+00 4.0e+00 5.0e+04 1.0e+00]]\n",
      "\n",
      "Linear Combination (z):\n",
      "[ -3827999.945 -13049999.975  -2435999.946 -14789999.973  -8699999.944]\n",
      "\n",
      "Predicted Values (y_pred):\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Loss: nan\n",
      "\n",
      "Gradient:\n",
      "[-6.00e-01 -1.80e+00 -1.72e+04 -6.00e-01]\n",
      "\n",
      "Updated Weights (w):\n",
      "[ 0.025  0.019 -2.     0.039]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21061/1836848120.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "/tmp/ipykernel_21061/1836848120.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
      "/tmp/ipykernel_21061/1836848120.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset: [Car Age, Mileage, Fuel Type]\n",
    "X = np.array([\n",
    "    [3, 22000, 1],\n",
    "    [6, 75000, 0],\n",
    "    [2, 14000, 1],\n",
    "    [8, 85000, 0],\n",
    "    [4, 50000, 1]\n",
    "])\n",
    "\n",
    "# Target Variable: Price Category (0 or 1)\n",
    "y = np.array([1, 0, 1, 0, 1])\n",
    "\n",
    "# Initialize Weights and Bias\n",
    "w = np.zeros(X.shape[1] + 1)  # [w0, w1, w2, w3]\n",
    "alpha = 0.01  # Learning Rate\n",
    "iterations = 10  # Reduced for easy viewing\n",
    "\n",
    "# Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Loss Function (Binary Cross Entropy)\n",
    "def loss_function(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Training using Gradient Descent\n",
    "for i in range(iterations):\n",
    "    # Add Bias Term (x0 = 1)\n",
    "    X_bias = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate Linear Combination (z = w0 + w1*x1 + w2*x2 + w3*x3)\n",
    "    z = np.dot(X_bias, w)\n",
    "\n",
    "    # Apply Sigmoid Function\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    # Compute Loss\n",
    "    loss = loss_function(y, y_pred)\n",
    "\n",
    "    # Calculate Gradients\n",
    "    gradient = np.dot(X_bias.T, (y_pred - y)) / len(y)\n",
    "\n",
    "    # Update Weights\n",
    "    w -= alpha * gradient\n",
    "\n",
    "    # Print All Values\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"X_bias (With Bias Term Added):\")\n",
    "    print(X_bias)\n",
    "    print(\"\\nLinear Combination (z):\")\n",
    "    print(z)\n",
    "    print(\"\\nPredicted Values (y_pred):\")\n",
    "    print(y_pred)\n",
    "    print(\"\\nLoss:\", loss)\n",
    "    print(\"\\nGradient:\")\n",
    "    print(gradient)\n",
    "    print(\"\\nUpdated Weights (w):\")\n",
    "    print(w)\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
